# ================================
# Linear Regression Cost Function
# with Visualization Helpers
# ================================

import numpy as np
import matplotlib.pyplot as plt

# custom utils
from lab_utils_uni import plt_intuition, plt_stationary, plt_update_onclick, soup_bowl

# set plotting style
plt.style.use('./deeplearning.mplstyle')

# -------------------------------
# Training data (first simple example)
# -------------------------------
x_train = np.array([1.0, 2.0])        # size in 1000 sqft
y_train = np.array([300.0, 500.0])    # price in $1000s


# -------------------------------
# Cost function implementation
# -------------------------------
def compute_cost(x, y, w, b): 
    """
    Computes the cost function for linear regression.
    
    Args:
        x (ndarray (m,)): Input data, m examples 
        y (ndarray (m,)): Target values
        w (float)       : Weight parameter
        b (float)       : Bias parameter  
    
    Returns:
        total_cost (float): The cost of using w, b as parameters
    """
    m = x.shape[0]        # number of training examples
    cost_sum = 0.0

    for i in range(m):
        f_wb = w * x[i] + b       # prediction
        cost = (f_wb - y[i])**2   # squared error
        cost_sum += cost
    
    total_cost = (1 / (2 * m)) * cost_sum
    return total_cost


# -------------------------------
# Visualization: intuition
# -------------------------------
plt_intuition(x_train, y_train)


# -------------------------------
# Training data (larger example)
# -------------------------------
x_train = np.array([1.0, 1.7, 2.0, 2.5, 3.0, 3.2])
y_train = np.array([250, 300, 480, 430, 630, 730])

# Close old plots if any
plt.close('all')

# Stationary plot with interactive updates
fig, ax, dyn_items = plt_stationary(x_train, y_train)
updater = plt_update_onclick(fig, ax, x_train, y_train, dyn_items)

# Soup bowl visualization of cost function
soup_bowl()
